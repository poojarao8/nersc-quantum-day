{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA Quantum 101\n",
    "    Important Links \n",
    "    \n",
    "    * Perlmutter Specific Instructions\n",
    "        https://github.com/poojarao8/nersc-quantum-day/blob/master/PerlmutterInstructions.md\n",
    "    * Installation (Docker recommended)\n",
    "        https://nvidia.github.io/cuda-quantum/latest/install.html \n",
    "    * Documentation\n",
    "        https://nvidia.github.io/cuda-quantum/latest/index.html\n",
    "    * CUDA Quantum Repo\n",
    "        https://github.com/NVIDIA/cuda-quantum\n",
    "    * Scaling Applications\n",
    "        https://nvidia.github.io/cuda-quantum/latest/examples/python/tutorials/multi_gpu_workflows.html\n",
    "\n",
    "\n",
    "    Outline \n",
    "\n",
    "    1. What is CUDA Quantum? \n",
    "    2. CUDA Quantum Kernels\n",
    "    3. CUDA Quantum Primitives\n",
    "        3.1 cudaq.sample() \n",
    "        3.2 cudaq.spin_op()\n",
    "        3.3 cudaq.observe()\n",
    "    4. Parameterized circuits \n",
    "    5. Noise-modeling\n",
    "    6. Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CUDA Quantum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - NVIDIA’s open-source platform for hybrid quantum-classical computing \n",
    "\n",
    "    - Built for high-performance, scalability, and ease-of-use\n",
    "\n",
    "    - As all valuable quantum applications of the future will be hybrid, CUDA Quantum enables users to develop performant hybrid applications that can easily scale to supercomputing scale systems like NERSC’s Perlmutter.\n",
    "\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "    <img src=\"figs/doe_excerpts.png\" alt=\"Image Title\" width=\"600\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. CUDA Quantum Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CUDA Quantum module\n",
    "import cudaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin by defining the `Kernel` that we will construct our\n",
    "# program with.\n",
    "kernel = cudaq.make_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we can allocate qubits to the kernel via `qalloc(qubit_count)`.\n",
    "# An empty call to `qalloc` will return a single qubit.\n",
    "qubit = kernel.qalloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can begin adding instructions to apply to this qubit!\n",
    "# Here we'll just add every non-parameterized\n",
    "# single qubit gates that are supported by CUDA Quantum.\n",
    "kernel.h(qubit)\n",
    "kernel.x(qubit)\n",
    "kernel.y(qubit)\n",
    "kernel.z(qubit)\n",
    "kernel.t(qubit)\n",
    "kernel.s(qubit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we add a measurement to the kernel so that we can sample\n",
    "# the measurement results on our simulator!\n",
    "kernel.mz(qubit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other methods and attributes available to the kernel object\n",
    "dir(kernel)\n",
    "#help(kernel.tdg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     3. Algorithmic primitives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Algorithmic primitives are common programming patterns that have \n",
    "  been implemented in the CUDA Quantum library.\n",
    "\n",
    "    3.1 cudaq.sample()\n",
    "    3.2 cudaq.observe()\n",
    "    3.3 cudaq.spin_op()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. cudaq.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      The sample() function performs multiple measurements of the \n",
    "      circuit(1000 shots by default) and returns a dictionary of the\n",
    "      measurement outcomes along with their respective counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can execute this kernel on the state vector simulator\n",
    "# by calling `cudaq.sample`. This will execute the provided kernel\n",
    "# `shots_count` number of times and return the sampled distribution\n",
    "# as a `cudaq.SampleResult` dictionary.\n",
    "sample_result = cudaq.sample(kernel)\n",
    "\n",
    "# Now let's take a look at the `SampleResult` we've gotten back!\n",
    "print(sample_result)  # or result.dump()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Putting it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "qubit = kernel.qalloc(2)\n",
    "                                  \n",
    "kernel.h(qubit)\n",
    "kernel.x(qubit)\n",
    "kernel.y(qubit)\n",
    "kernel.z(qubit)\n",
    "kernel.t(qubit)\n",
    "kernel.s(qubit)\n",
    "\n",
    "kernel.mz(qubit)\n",
    "\n",
    "# 1000 is the default\n",
    "sample_result = cudaq.sample(kernel, shots_count=2000) \n",
    "\n",
    "print(sample_result)  # or sample_result.dump() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data from sample\n",
    "\n",
    "print(f\"most probable = {sample_result.most_probable()}\")\n",
    "print(f\"expectation_value = {sample_result.expectation()}\")\n",
    "print(f\"count = {sample_result.count('1')}\")\n",
    "print(f\"probability = {sample_result.probability('1')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear results, result should now be empty\n",
    "sample_result.clear()\n",
    "print(sample_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3.2. cudaq.spin_op()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     \n",
    "    The spin_op represents a sum of Pauli tensor products. \n",
    "    \n",
    "    - Typical algebraic operations can be used to compose larger,\n",
    "    more complex Pauli tensor products and their sums. \n",
    "\n",
    "Let's take the Hamitonian H such that, H  = $Z_0 \\otimes I_1 + I_0 \\otimes X_1 + Y_0 \\otimes I_1 + Y_0 \\otimes Y_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the spin_op\n",
    "from cudaq import spin\n",
    "\n",
    "# the obseravle \n",
    "hamiltonian = spin.z(0) + spin.x(1) + spin.y(0) + spin.y(0)*spin.y(1)\n",
    "\n",
    "# add some more terms\n",
    "for i in range(2):\n",
    "  hamiltonian += -2.0*spin.z(i)*spin.z(i+1)\n",
    "\n",
    "print(hamiltonian)\n",
    "print(hamiltonian.to_matrix())\n",
    "print(hamiltonian.to_sparse_matrix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(hamiltonian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. cudaq.observe()\n",
    "\n",
    "Compute the expected value of the observable, i.e., $\\bra{\\psi}H\\ket{\\psi}$, where $H$ is a cudaq spin_op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the spin_op\n",
    "from cudaq import spin\n",
    "\n",
    "# the obseravle \n",
    "hamiltonian = spin.z(0) + spin.x(1) + spin.y(0) + spin.y(0)*spin.y(1)\n",
    "\n",
    "# First we need to construct a cuda quantum kernel\n",
    "kernel = cudaq.make_kernel()\n",
    "qreg = kernel.qalloc(2)\n",
    "kernel.x(qreg[0])\n",
    "\n",
    "# The cudaq.observe() takes the quantum circuit and the observable as input params\n",
    "observe_result = cudaq.observe(kernel, hamiltonian, shots_count=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(observe_result.dump())\n",
    "observe_result.expectation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a complete list of attributes\n",
    "# dir (observe_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Parameterized circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "# the obserable \n",
    "hamiltonian = 5.907 - 2.1433 * spin.x(0) * spin.x(1) \\\n",
    "            - 2.1433 * spin.y(0) * spin.y(1) + 0.21829 * spin.z(0) \\\n",
    "            - 6.125 * spin.z(1)\n",
    "\n",
    "# parameterized cudaq kernel, the parameter is of type float\n",
    "kernel, theta = cudaq.make_kernel(float)\n",
    "q = kernel.qalloc(2)\n",
    "kernel.x(q[0])\n",
    "kernel.ry(theta, q[1])\n",
    "kernel.cx(q[1], q[0])\n",
    "\n",
    "# observe() takes the kernel, the observable and the kernel paramter(s)\n",
    "# as args\n",
    "observe_result = cudaq.observe(kernel, hamiltonian, .59)\n",
    "observe_result.expectation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Noise modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Noise can be represnted mathematically using the Kraus operators.\n",
    "    \n",
    "\\begin{equation*}\n",
    "\\rho \\mapsto {\\cal{N}}(\\rho) = \\sum_{j} K_j \\rho K_j^{\\dag}\n",
    "\\end{equation*}\n",
    "\n",
    "    with the condition that \n",
    "    \n",
    "\\begin{equation*}\n",
    "\\sum_{j} K_j K_j^{\\dag} = \\mathbb{I}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    A single-qubit bit-flip error can be expressed as:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\rho = (1-p) \\rho + p X\\rho X \n",
    "\\end{equation*}\n",
    "    with p in [0,1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "\n",
    "# Set the target to our density matrix simulator.\n",
    "cudaq.set_target('density-matrix-cpu')\n",
    "\n",
    "# We will begin by defining an empty noise model that we will add\n",
    "# these decoherence channels to.\n",
    "noise = cudaq.NoiseModel()\n",
    "\n",
    "# Bit flip channel with `1.0` probability of the qubit flipping 180 degrees.\n",
    "bit_flip = cudaq.BitFlipChannel(1.0)\n",
    "# We will apply this channel to any X gate on the qubit, giving each X-gate\n",
    "# a probability of `1.0` of undergoing an extra X-gate.\n",
    "noise.add_channel('x', [0], bit_flip)\n",
    "\n",
    "# construct a circuit\n",
    "kernel = cudaq.make_kernel()\n",
    "qubit = kernel.qalloc()\n",
    "\n",
    "# Apply an X-gate to the qubit.\n",
    "# It will remain in the |1> state with a probability of `1 - p = 0.0`.\n",
    "kernel.x(qubit)\n",
    "kernel.mz(qubit)\n",
    "\n",
    "# noisy simulation\n",
    "noisy_result = cudaq.sample(kernel, noise_model=noise)\n",
    "noisy_result.dump()\n",
    "\n",
    "# noiseless simulation\n",
    "noiseless_result = cudaq.sample(kernel)\n",
    "noiseless_result.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Custom Noise Model\n",
    "\n",
    "     Here, we demonstrate a custom noise model with the same Kraus operators as in the ampltiude damping channel, but following the same template we can build other noise models such as the Pauli noise model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "import numpy as np\n",
    "\n",
    "# Set the target to our density matrix simulator.\n",
    "cudaq.set_target('density-matrix-cpu')\n",
    "\n",
    "# We will begin by defining an empty noise model that we will add\n",
    "# our Kraus Channel to.\n",
    "noise = cudaq.NoiseModel()\n",
    "\n",
    "# We will define our Kraus Operators within functions, as to\n",
    "# allow for easy control over the noise probability.\n",
    "def kraus_operators(probability):\n",
    "    \"\"\"See Nielsen, Chuang Chapter 8.3.5 for definition source.\"\"\"\n",
    "    kraus_0 = np.array([[1, 0], [0, np.sqrt(1 - probability)]],\n",
    "                       dtype=np.complex128)\n",
    "    kraus_1 = np.array([[0, 0], [np.sqrt(probability), 0]], dtype=np.complex128)\n",
    "    return [kraus_0, kraus_1]\n",
    "\n",
    "\n",
    "# Manually defined amplitude damping channel with `1.0` probability\n",
    "# of the qubit decaying to the ground state.\n",
    "amplitude_damping = cudaq.KrausChannel(kraus_operators(1.0))\n",
    "# We will apply this channel to any Hadamard gate on the qubit.\n",
    "noise.add_channel('h', [0], amplitude_damping)\n",
    "\n",
    "# construct a simple kernel\n",
    "kernel = cudaq.make_kernel()\n",
    "qubit = kernel.qalloc()\n",
    "kernel.h(qubit)\n",
    "kernel.mz(qubit)\n",
    "\n",
    "# noisy\n",
    "noisy_result = cudaq.sample(kernel, noise_model=noise)\n",
    "noisy_result.dump()\n",
    "\n",
    "# noiseless\n",
    "noiseless_result = cudaq.sample(kernel)\n",
    "noiseless_result.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single-gpu speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "\n",
    "#cudaq.set_target(\"default\") # cpu\n",
    "cudaq.set_target(\"nvidia\") # single gpu acceleration\n",
    "\n",
    "def ghz_state(N):\n",
    "    kernel = cudaq.make_kernel()\n",
    "    q = kernel.qalloc(N)\n",
    "    kernel.h(q[0])\n",
    "    for i in range(N - 1):\n",
    "      kernel.cx(q[i], q[i + 1])\n",
    " \n",
    "    kernel.mz(q)\n",
    "    return kernel\n",
    "\n",
    "n = 32 \n",
    "print(\"Preparing GHZ state for\", n, \"qubits.\")\n",
    "kernel = ghz_state(n)\n",
    "counts = cudaq.sample(kernel)\n",
    "counts.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling applications in CUDA Quantum\n",
    "Main reference: https://nvidia.github.io/cuda-quantum/latest/examples/python/tutorials/multi_gpu_workflows.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Targets\n",
    "\n",
    "    - A combination of quantum circuit simulators and hardware.\n",
    "    - Allows you to switch between QPUs, CPUs and GPUs.\n",
    "    - The default target provides a state vector simulator based on the CPU-only, OpenMP threaded Q++ library. \n",
    "\n",
    "\n",
    "Available Targets¶\n",
    "\n",
    "        default: The default qpp based CPU backend which is multithreaded to maximise the usage of available cores on your system.\n",
    "\n",
    "        nvidia: GPU based backend which accelerates quantum circuit simulation on NVIDIA GPUs powered by cuQuantum.\n",
    "\n",
    "        nvidia-mqpu: Enables users to program workflows utilizing multiple quantum processors enabled today by GPU emulation.\n",
    "\n",
    "        nvidia-mgpu: Allows for scaling circuit simulation beyond what is feasible with any QPU today.\n",
    "\n",
    "        density-matrix-cpu: Noisy simulations via density matrix calculations. CPU only for now with GPU support coming soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all the availble targets for your system\n",
    "import cudaq\n",
    "\n",
    "targets = cudaq.get_targets()\n",
    "\n",
    "for target in targets:\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Some  ways to scale your application:\n",
    "  \n",
    "    1. Increasing the number of qubits (weak scaling)\n",
    "    \n",
    "            - mgpu backend\n",
    "    \n",
    "    2. Distributing the circuit execution (strong scaling)\n",
    "            2.1 asynchronous sampling\n",
    "            2.2 Hamiltonian batching\n",
    "            2.3 Parameter batching\n",
    "\n",
    "            - mqpu backend\n",
    "            - Each gpu acts as a virtual qpu\n",
    "\n",
    "         As a rule of thumb, we can parallelize over any of the input parameters to `cudaq.sample()` or `cudaq.observe()` - kernel, hamiltonian, kernel parameters, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple NVIDIA GPUs for the mgpu backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - The increase in qubit count leads to an exponential increase in the size of the statevector.\n",
    "    \n",
    "    - The nvidia-mgpu target allows for scaling the qubit count by pooling memory from GPUs across multiple nodes.\n",
    "\n",
    "    - Execution on the nvidia-mgpu backed is enabled via `srun` on Perlmutter.\n",
    "\n",
    "    - To test this, run the GHZ state prep example https://github.com/poojarao8/nersc-quantum-day/blob/master/ghz.py using the instructions from here https://github.com/poojarao8/nersc-quantum-day/blob/master/PerlmutterInstructions.md.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                            \n",
    "                            GHZ state prep on Perlmutter\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "    <img src=\"figs/qubit_scaling.png\" alt=\"Image Title\" width=\"200\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous sampling via mqpu backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq \n",
    "\n",
    "cudaq.set_target(\"nvidia-mqpu\")\n",
    "target = cudaq.get_target()\n",
    "num_qpus = target.num_qpus()\n",
    "print(\"Number of QPUs:\", num_qpus)\n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "qubits = kernel.qalloc(2)\n",
    "kernel.h(qubits[0])\n",
    "kernel.cx(qubits[0], qubits[1])\n",
    "kernel.mz(qubits)\n",
    "\n",
    "futures = []\n",
    "for i in range(num_qpus):\n",
    "  futures.append(cudaq.sample_async(kernel, qpu_id=i))\n",
    "  \n",
    "\n",
    "for count in futures:\n",
    "    print(count.get())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      Asynchronous expectation value computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "qubit = kernel.qalloc()\n",
    "kernel.x(qubit)\n",
    "\n",
    "# Measuring in the Z-basis.\n",
    "hamiltonian = spin.z(0)\n",
    "\n",
    "# Call `cudaq.observe()` at the specified number of shots.\n",
    "future = cudaq.observe_async(kernel=kernel,\n",
    "                            spin_operator=hamiltonian,\n",
    "                            qpu_id=0,\n",
    "                            shots_count=2000)\n",
    "observe_result = future.get()\n",
    "got_expectation = observe_result.expectation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                    Hamiltonian term distribution over multiple QPUs\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "    <img src=\"figs/hamiltonian_batch.png\" alt=\"Image Title\" width=\"500\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "\n",
    "cudaq.set_target(\"nvidia-mqpu\")\n",
    "\n",
    "qubit_count = 15\n",
    "term_count = 100\n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "qubits = kernel.qalloc(qubit_count)\n",
    "kernel.h(qubits[0])\n",
    "\n",
    "for i in range(1, qubit_count):\n",
    "    kernel.cx(qubits[0], qubits[i])\n",
    "\n",
    "# We create a random hamiltonian with several terms\n",
    "hamiltonian = cudaq.SpinOperator.random(qubit_count, term_count)\n",
    "\n",
    "# The observe calls allows us to calculate the expectation value of the Hamiltonian,\n",
    "# batches the terms, and distributes them over the multiple QPU's/GPUs.\n",
    "# expectation = cudaq.observe(kernel, hamiltonian)  # Single node, single GPU.\n",
    "\n",
    "expectation = cudaq.observe(kernel, hamiltonian, \n",
    "                        execution=cudaq.parallel.thread)  # Single node, multi-GPU.\n",
    "\n",
    "# expectation = cudaq.observe(kernel, hamiltonian, \n",
    "#                       execution= cudaq.parallel.mpi) # Multi-node, multi-GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    More on workflows enabled by the use of multiple gpus:\n",
    "https://nvidia.github.io/cuda-quantum/latest/examples/python/tutorials/multi_gpu_workflows.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other useful things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Adjoing of a kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " import cudaq \n",
    "\n",
    "# Create a kernel and do some operations\n",
    "other_kernel = cudaq.make_kernel()\n",
    "other_qubit = other_kernel.qalloc()\n",
    "other_kernel.x(other_qubit)\n",
    "\n",
    "# Create a kernel, which'll be the adjoint of other_kernel \n",
    "kernel = cudaq.make_kernel()\n",
    "kernel.adjoint(other_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Conditional Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \n",
      "  __global__ : { 0:30 }\n",
      "   auto_register_0 : { 1:30 }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    " # The conditional measurement functionality of `cudaq.kernel`\n",
    "import cudaq \n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "qubit = kernel.qalloc()\n",
    "\n",
    "def then_function():\n",
    "    kernel.x(qubit)\n",
    "\n",
    "kernel.x(qubit)\n",
    "\n",
    "# Measure the qubit.\n",
    "measurement_ = kernel.mz(qubit)\n",
    "# Apply `then_function` to the `kernel` if\n",
    "# the qubit was measured in the 1-state.\n",
    "kernel.c_if(measurement_, then_function)\n",
    "\n",
    "# Measure the qubit again.\n",
    "result = cudaq.sample(kernel, shots_count=30)\n",
    "result.dump()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Algorithms\n",
    "\n",
    "    Variational algorithms in CUDA Quantum typically leverage the `cudaq.observe(...)` function in tandem with the `cudaq.optimizer`.\n",
    "\n",
    "    One can choose an optimization strategy provided as specific sub-types of the `cudaq.optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9999999999999997 [0.0]\n",
      "0.0 [1.5707963267948966]\n",
      "-1.9999999999999996 [-1.5707963267948966]\n",
      "-0.9999999999999997 [-3.141592653589793]\n",
      "-0.9999999999999997 [0.0]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "# Parameterized circuit with theta as the parameter\n",
    "kernel, theta = cudaq.make_kernel(list)\n",
    "qreg = kernel.qalloc(2)\n",
    "kernel.x(qreg[0])\n",
    "kernel.ry(theta[0], qreg[1])\n",
    "\n",
    "\n",
    "# Observable  \n",
    "hamiltonian = spin.z(0) + spin.x(1) + spin.y(0)\n",
    "\n",
    "# Initialize the gradient-free optimizer COBYLA\n",
    "optimizer = cudaq.optimizers.COBYLA()\n",
    "\n",
    "# Specify the number of iterations (optional)\n",
    "optimizer.max_iterations = 5\n",
    "\n",
    "def cost_function(x):\n",
    "    # cudaq.observe() produces the expected value of a specified observable wrt a given parameterized ansatz at given params.\n",
    "    # This value is the cost function wrt which we are optimizing.\n",
    "    observeResult = cudaq.observe(kernel, hamiltonian, x)\n",
    "    print (observeResult.expectation(), x)\n",
    "    return observeResult.expectation()\n",
    "\n",
    "# Carry out the optimization\n",
    "opt_value, opt_theta = optimizer.optimize(dimensions=1, function=cost_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    VQE wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "minimized <H> = -1.9999999999999996\n",
      "optimal theta = -1.5707963267948966\n"
     ]
    }
   ],
   "source": [
    " # Import the necessary modules\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "# Parameterized circuit with theta as the parameter\n",
    "kernel, theta = cudaq.make_kernel(list)\n",
    "qreg = kernel.qalloc(2)\n",
    "kernel.x(qreg[0])\n",
    "kernel.ry(theta[0], qreg[1])\n",
    "\n",
    "# Hamiltonian operator \n",
    "hamiltonian = spin.z(0) + spin.x(1) + spin.y(0)\n",
    "\n",
    "# Initialize the gradient-free optimizer COBYLA\n",
    "optimizer = cudaq.optimizers.COBYLA()\n",
    "\n",
    "# Specify the number of iterations (optional)\n",
    "optimizer.max_iterations = 5\n",
    "\n",
    "# Carry out the optimization\n",
    "opt_value, opt_theta = cudaq.vqe(kernel=kernel, \n",
    "                        spin_operator=hamiltonian,\n",
    "                        optimizer=optimizer,\n",
    "                        parameter_count=1)\n",
    "\n",
    "print(f\"\\nminimized <H> = {round(opt_value,16)}\")\n",
    "print(f\"optimal theta = {round(opt_theta[0],16)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
