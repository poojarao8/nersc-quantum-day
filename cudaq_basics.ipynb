{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA Quantum 101\n",
    "    Important Links \n",
    "    \n",
    "    * Perlmutter Specific Instructions\n",
    "        https://github.com/poojarao8/nersc-quantum-day/blob/master/PerlmutterInstructions.md\n",
    "    * Installation (Docker recommended)\n",
    "        https://nvidia.github.io/cuda-quantum/latest/install.html \n",
    "    * Documentation\n",
    "        https://nvidia.github.io/cuda-quantum/latest/index.html\n",
    "    * CUDA Quantum Repo\n",
    "        https://github.com/NVIDIA/cuda-quantum\n",
    "\n",
    "\n",
    "    Outline \n",
    "\n",
    "    1. What is CUDA Quantum? \n",
    "    2. CUDA Quantum Kernels\n",
    "    3. CUDA Quantum Primitives\n",
    "        3.1 cudaq.sample() \n",
    "        3.2 cudaq.spin_op()\n",
    "        3.3 cudaq.observe()\n",
    "    4. Parameterized circuits \n",
    "    5. Noise-modeling\n",
    "    6. Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CUDA Quantum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                            Hybrid workflows\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "    <img src=\"pics/doe_excerpts.png\" alt=\"Image Title\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "        CUDA Quantum is NVIDIA’s open-source platform for hybrid quantum-classical computing, built for high-performance, scalability, and ease-of-use. As all valuable quantum applications of the future will be hybrid, CUDA Quantum enables users to develop performant hybrid applications that can easily scale to supercomputing scale systems like NERSC’s Perlmutter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. CUDA Quantum Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CUDA Quantum module\n",
    "import cudaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin by defining the `Kernel` that we will construct our\n",
    "# program with.\n",
    "kernel = cudaq.make_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we can allocate qubits to the kernel via `qalloc(qubit_count)`.\n",
    "# An empty call to `qalloc` will return a single qubit.\n",
    "qubit = kernel.qalloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can begin adding instructions to apply to this qubit!\n",
    "# Here we'll just add every non-parameterized\n",
    "# single qubit gates that are supported by CUDA Quantum.\n",
    "kernel.h(qubit)\n",
    "kernel.x(qubit)\n",
    "kernel.y(qubit)\n",
    "kernel.z(qubit)\n",
    "kernel.t(qubit)\n",
    "kernel.s(qubit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cudaq._pycudaq.QuakeValue at 0x7f95fda527b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we add a measurement to the kernel so that we can sample\n",
    "# the measurement results on our simulator!\n",
    "kernel.mz(qubit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'adjoint',\n",
       " 'apply_call',\n",
       " 'argument_count',\n",
       " 'arguments',\n",
       " 'c_if',\n",
       " 'ch',\n",
       " 'control',\n",
       " 'cr1',\n",
       " 'crx',\n",
       " 'cry',\n",
       " 'crz',\n",
       " 'cs',\n",
       " 'ct',\n",
       " 'cx',\n",
       " 'cy',\n",
       " 'cz',\n",
       " 'exp_pauli',\n",
       " 'fermionic_swap',\n",
       " 'for_loop',\n",
       " 'givens_rotation',\n",
       " 'h',\n",
       " 'mx',\n",
       " 'my',\n",
       " 'mz',\n",
       " 'name',\n",
       " 'qalloc',\n",
       " 'r1',\n",
       " 'reset',\n",
       " 'rx',\n",
       " 'ry',\n",
       " 'rz',\n",
       " 's',\n",
       " 'sdg',\n",
       " 'swap',\n",
       " 't',\n",
       " 'tdg',\n",
       " 'to_quake',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other methods and attributes available to the kernel object\n",
    "dir(kernel)\n",
    "#help(kernel.tdg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     3. Algorithmic primitives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Algorithmic primitives are common programming patterns that have \n",
    "  been implemented in the CUDA Quantum library.\n",
    "\n",
    "    3.1 cudaq.sample()\n",
    "    3.2 cudaq.observe()\n",
    "    3.3 cudaq.spin_op()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. cudaq.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      The sample() function performs multiple measurements of the \n",
    "      circuit(1000 shots by default) and returns a dictionary of the\n",
    "      measurement outcomes along with their respective counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 0:488 1:512 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finally, we can execute this kernel on the state vector simulator\n",
    "# by calling `cudaq.sample`. This will execute the provided kernel\n",
    "# `shots_count` number of times and return the sampled distribution\n",
    "# as a `cudaq.SampleResult` dictionary.\n",
    "sample_result = cudaq.sample(kernel)\n",
    "\n",
    "# Now let's take a look at the `SampleResult` we've gotten back!\n",
    "print(sample_result)  # or result.dump()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Putting it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 00:520 01:507 10:510 11:463 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "qubit = kernel.qalloc(2)\n",
    "                                  \n",
    "kernel.h(qubit)\n",
    "kernel.x(qubit)\n",
    "kernel.y(qubit)\n",
    "kernel.z(qubit)\n",
    "kernel.t(qubit)\n",
    "kernel.s(qubit)\n",
    "\n",
    "kernel.mz(qubit)\n",
    "\n",
    "# 1000 is the default\n",
    "sample_result = cudaq.sample(kernel, shots_count=2000) \n",
    "\n",
    "print(sample_result)  # or sample_result.dump() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most probable = 00\n",
      "expectation_value = -0.016999999999999987\n",
      "count = 0\n",
      "probability = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Extracting data from sample\n",
    "\n",
    "print(f\"most probable = {sample_result.most_probable()}\")\n",
    "print(f\"expectation_value = {sample_result.expectation()}\")\n",
    "print(f\"count = {sample_result.count('1')}\")\n",
    "print(f\"probability = {sample_result.probability('1')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clear results, result should now be empty\n",
    "sample_result.clear()\n",
    "print(sample_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3.2. cudaq.spin_op()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     \n",
    "    The spin_op represents a sum of Pauli tensor products. \n",
    "    \n",
    "    - Typical algebraic operations can be used to compose larger,\n",
    "    more complex Pauli tensor products and their sums. \n",
    "\n",
    "Let's take the Hamitonian H such that, H  = $Z_0 \\otimes I_1 + I_0 \\otimes X_1 + Y_0 \\otimes I_1 + Y_0 \\otimes Y_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2+0j] IZZ\n",
      "[1+0j] ZII\n",
      "[1+0j] YII\n",
      "[1+0j] IXI\n",
      "[1+0j] YYI\n",
      "[-2+0j] ZZI\n",
      "\n",
      "(-3,0)  (0,0)  (1,0)  (0,0)  (0,1)  (0,0) (-1,0)  (0,0)\n",
      " (0,0)  (1,0)  (0,0)  (1,0)  (0,0)  (0,1)  (0,0) (-1,0)\n",
      " (1,0)  (0,0)  (5,0)  (0,0)  (1,0)  (0,0)  (0,1)  (0,0)\n",
      " (0,0)  (1,0)  (0,0)  (1,0)  (0,0)  (1,0)  (0,0)  (0,1)\n",
      "(0,-1)  (0,0)  (1,0)  (0,0) (-1,0)  (0,0)  (1,0)  (0,0)\n",
      " (0,0) (0,-1)  (0,0)  (1,0)  (0,0)  (3,0)  (0,0)  (1,0)\n",
      "(-1,0)  (0,0) (0,-1)  (0,0)  (1,0)  (0,0) (-1,0)  (0,0)\n",
      " (0,0) (-1,0)  (0,0) (0,-1)  (0,0)  (1,0)  (0,0) (-5,0)\n",
      "\n",
      "([(-3+0j), (1+0j), 1j, (-1+0j), (1+0j), (1+0j), 1j, (-1+0j), (1+0j), (5+0j), (1+0j), 1j, (1+0j), (1+0j), (1+0j), 1j, -1j, (1+0j), (-1+0j), (1+0j), -1j, (1+0j), (3+0j), (1+0j), (-1+0j), -1j, (1+0j), (-1+0j), (-1+0j), -1j, (1+0j), (-5+0j)], [0, 2, 4, 6, 1, 3, 5, 7, 0, 2, 4, 6, 1, 3, 5, 7, 0, 2, 4, 6, 1, 3, 5, 7, 0, 2, 4, 6, 1, 3, 5, 7], [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "# Importing the spin_op\n",
    "from cudaq import spin\n",
    "\n",
    "# the obseravle \n",
    "hamiltonian = spin.z(0) + spin.x(1) + spin.y(0) + spin.y(0)*spin.y(1)\n",
    "\n",
    "# add some more terms\n",
    "for i in range(2):\n",
    "  hamiltonian += -2.0*spin.z(i)*spin.z(i+1)\n",
    "\n",
    "print(hamiltonian)\n",
    "print(hamiltonian.to_matrix())\n",
    "print(hamiltonian.to_sparse_matrix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__radd__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmul__',\n",
       " '__rsub__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " 'distribute_terms',\n",
       " 'dump',\n",
       " 'for_each_pauli',\n",
       " 'for_each_term',\n",
       " 'from_word',\n",
       " 'get_coefficient',\n",
       " 'get_qubit_count',\n",
       " 'get_raw_data',\n",
       " 'get_term_count',\n",
       " 'is_identity',\n",
       " 'random',\n",
       " 'serialize',\n",
       " 'to_matrix',\n",
       " 'to_sparse_matrix',\n",
       " 'to_string']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(hamiltonian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. cudaq.observe()\n",
    "\n",
    "Compute the expected value of the observable, i.e., $\\bra{\\psi}H\\ket{\\psi}$, where $H$ is a cudaq spin_op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the spin_op\n",
    "from cudaq import spin\n",
    "\n",
    "# the obseravle \n",
    "hamiltonian = spin.z(0) + spin.x(1) + spin.y(0) + spin.y(0)*spin.y(1)\n",
    "\n",
    "# First we need to construct a cuda quantum kernel\n",
    "kernel = cudaq.make_kernel()\n",
    "qreg = kernel.qalloc(2)\n",
    "kernel.x(qreg[0])\n",
    "\n",
    "# The cudaq.observe() takes the quantum circuit and the observable as input params\n",
    "observe_result = cudaq.observe(kernel, hamiltonian, shots_count=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{ \n",
      "  __global__ : { }\n",
      "   ZI : { 1:1000 }\n",
      "   YI : { 1:497 0:503 }\n",
      "   IX : { 1:453 0:547 }\n",
      "   YY : { 11:226 10:249 01:280 00:245 }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.958"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(observe_result.dump())\n",
    "observe_result.expectation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a complete list of attributes\n",
    "# dir (observe_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Parameterized circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "# the obserable \n",
    "hamiltonian = 5.907 - 2.1433 * spin.x(0) * spin.x(1) \\\n",
    "            - 2.1433 * spin.y(0) * spin.y(1) + 0.21829 * spin.z(0) \\\n",
    "            - 6.125 * spin.z(1)\n",
    "\n",
    "# parameterized cudaq kernel, the parameter is of type float\n",
    "kernel, theta = cudaq.make_kernel(float)\n",
    "q = kernel.qalloc(2)\n",
    "kernel.x(q[0])\n",
    "kernel.ry(theta, q[1])\n",
    "kernel.cx(q[1], q[0])\n",
    "\n",
    "# observe() takes the kernel, the observable and the kernel paramter(s)\n",
    "# as args\n",
    "observe_result = cudaq.observe(kernel, hamiltonian, .59)\n",
    "observe_result.expectation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Noise modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Noise can be represnted mathematically using the Kraus operators.\n",
    "    \n",
    "\\begin{equation*}\n",
    "\\rho \\mapsto {\\cal{N}}(\\rho) = \\sum_{j} K_j \\rho K_j^{\\dag}\n",
    "\\end{equation*}\n",
    "\n",
    "    with the condition that \n",
    "    \n",
    "\\begin{equation*}\n",
    "\\sum_{j} K_j K_j^{\\dag} = \\mathbb{I}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    A single-qubit bit-flip error can be expressed as:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\rho = (1-p) \\rho + p X\\rho X \n",
    "\\end{equation*}\n",
    "    with p in [0,1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "\n",
    "# Set the target to our density matrix simulator.\n",
    "cudaq.set_target('density-matrix-cpu')\n",
    "\n",
    "# We will begin by defining an empty noise model that we will add\n",
    "# these decoherence channels to.\n",
    "noise = cudaq.NoiseModel()\n",
    "\n",
    "# Bit flip channel with `1.0` probability of the qubit flipping 180 degrees.\n",
    "bit_flip = cudaq.BitFlipChannel(1.0)\n",
    "# We will apply this channel to any X gate on the qubit, giving each X-gate\n",
    "# a probability of `1.0` of undergoing an extra X-gate.\n",
    "noise.add_channel('x', [0], bit_flip)\n",
    "\n",
    "# construct a circuit\n",
    "kernel = cudaq.make_kernel()\n",
    "qubit = kernel.qalloc()\n",
    "\n",
    "# Apply an X-gate to the qubit.\n",
    "# It will remain in the |1> state with a probability of `1 - p = 0.0`.\n",
    "kernel.x(qubit)\n",
    "kernel.mz(qubit)\n",
    "\n",
    "# noisy simulation\n",
    "noisy_result = cudaq.sample(kernel, noise_model=noise)\n",
    "noisy_result.dump()\n",
    "\n",
    "# noiseless simulation\n",
    "noiseless_result = cudaq.sample(kernel)\n",
    "noiseless_result.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Custom Noise Model\n",
    "\n",
    "     Here, we demonstrate a custom noise model with the same Kraus operators as in the ampltiude damping channel, but following the same template we can build other noise models such as the Pauli noise model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "import numpy as np\n",
    "\n",
    "# Set the target to our density matrix simulator.\n",
    "cudaq.set_target('density-matrix-cpu')\n",
    "\n",
    "# We will begin by defining an empty noise model that we will add\n",
    "# our Kraus Channel to.\n",
    "noise = cudaq.NoiseModel()\n",
    "\n",
    "# We will define our Kraus Operators within functions, as to\n",
    "# allow for easy control over the noise probability.\n",
    "def kraus_operators(probability):\n",
    "    \"\"\"See Nielsen, Chuang Chapter 8.3.5 for definition source.\"\"\"\n",
    "    kraus_0 = np.array([[1, 0], [0, np.sqrt(1 - probability)]],\n",
    "                       dtype=np.complex128)\n",
    "    kraus_1 = np.array([[0, 0], [np.sqrt(probability), 0]], dtype=np.complex128)\n",
    "    return [kraus_0, kraus_1]\n",
    "\n",
    "\n",
    "# Manually defined amplitude damping channel with `1.0` probability\n",
    "# of the qubit decaying to the ground state.\n",
    "amplitude_damping = cudaq.KrausChannel(kraus_operators(1.0))\n",
    "# We will apply this channel to any Hadamard gate on the qubit.\n",
    "noise.add_channel('h', [0], amplitude_damping)\n",
    "\n",
    "# construct a simple kernel\n",
    "kernel = cudaq.make_kernel()\n",
    "qubit = kernel.qalloc()\n",
    "kernel.h(qubit)\n",
    "kernel.mz(qubit)\n",
    "\n",
    "# noisy\n",
    "noisy_result = cudaq.sample(kernel, noise_model=noise)\n",
    "noisy_result.dump()\n",
    "\n",
    "# noiseless\n",
    "noiseless_result = cudaq.sample(kernel)\n",
    "noiseless_result.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single-gpu speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "\n",
    "#cudaq.set_target(\"default\") # cpu\n",
    "cudaq.set_target(\"nvidia\") # single gpu acceleration\n",
    "\n",
    "def ghz_state(N):\n",
    "    kernel = cudaq.make_kernel()\n",
    "    q = kernel.qalloc(N)\n",
    "    kernel.h(q[0])\n",
    "    for i in range(N - 1):\n",
    "      kernel.cx(q[i], q[i + 1])\n",
    " \n",
    "    kernel.mz(q)\n",
    "    return kernel\n",
    "\n",
    "n = 32 \n",
    "print(\"Preparing GHZ state for\", n, \"qubits.\")\n",
    "kernel = ghz_state(n)\n",
    "counts = cudaq.sample(kernel)\n",
    "counts.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling applications in CUDA Quantum\n",
    "Main reference: https://nvidia.github.io/cuda-quantum/latest/examples/python/tutorials/multi_gpu_workflows.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ### NVIDIA Targets\n",
    "\n",
    "    - A combination of quantum circuit simulators and hardware.\n",
    "    - Allows you to switch between QPUs, CPUs and GPUs.\n",
    "    - The default target provides a state vector simulator based on the CPU-only, OpenMP threaded Q++ library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all the availble targets for your system\n",
    "import cudaq\n",
    "\n",
    "targets = cudaq.get_targets()\n",
    "\n",
    "for target in targets:\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Some  ways to scale your application:\n",
    "  \n",
    "    1. Increasing the number of qubits (weak scaling)\n",
    "    \n",
    "            - mgpu backend\n",
    "    \n",
    "    2. Distributing the circuit execution (strong scaling)\n",
    "            2.1 asynchronous sampling\n",
    "            2.2 Hamiltonian batching\n",
    "            2.3 Parameter batching\n",
    "\n",
    "            - mqpu backend\n",
    "            - Each gpu acts as a virtual qpu\n",
    "\n",
    "         As a rule of thumb, we can parallelize over any of the input parameters to `cudaq.sample()` or `cudaq.observe()` - kernel, hamiltonian, kernel parameters, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple NVIDIA GPUs for the mgpu backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - The increase in qubit count leads to an exponential increase in the size of the statevector.\n",
    "    \n",
    "    - The nvidia-mgpu target allows for scaling the qubit count by pooling memory from GPUs across multiple nodes.\n",
    "\n",
    "    - Execution on the nvidia-mgpu backed is enabled via `srun` on Perlmutter.\n",
    "\n",
    "    - To test this, run the GHZ state prep example https://github.com/poojarao8/nersc-quantum-day/blob/master/ghz.py using the instructions from here https://github.com/poojarao8/nersc-quantum-day/blob/master/PerlmutterInstructions.md.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                            \n",
    "                            GHZ state prep on Perlmutter\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "    <img src=\"pics/qubit_scaling.png\" alt=\"Image Title\" width=\"200\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous sampling via mqpu backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq \n",
    "\n",
    "cudaq.set_target(\"nvidia-mqpu\")\n",
    "target = cudaq.get_target()\n",
    "num_qpus = target.num_qpus()\n",
    "print(\"Number of QPUs:\", num_qpus)\n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "qubits = kernel.qalloc(2)\n",
    "kernel.h(qubits[0])\n",
    "kernel.cx(qubits[0], qubits[1])\n",
    "kernel.mz(qubits)\n",
    "\n",
    "futures = []\n",
    "for i in range(num_qpus):\n",
    "  futures.append(cudaq.sample_async(kernel, qpu_id=i))\n",
    "  \n",
    "\n",
    "for count in futures:\n",
    "    print(count.get())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      Asynchronous expectation value computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "qubit = kernel.qalloc()\n",
    "kernel.x(qubit)\n",
    "\n",
    "# Measuring in the Z-basis.\n",
    "hamiltonian = spin.z(0)\n",
    "\n",
    "# Call `cudaq.observe()` at the specified number of shots.\n",
    "future = cudaq.observe_async(kernel=kernel,\n",
    "                            spin_operator=hamiltonian,\n",
    "                            qpu_id=0,\n",
    "                            shots_count=2000)\n",
    "observe_result = future.get()\n",
    "got_expectation = observe_result.expectation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                             Hamiltonian term distribution over multiple QPUs\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "    <img src=\"pics/hamiltonian_batch.png\" alt=\"Image Title\" width=\"500\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "\n",
    "cudaq.set_target(\"nvidia-mqpu\")\n",
    "\n",
    "qubit_count = 15\n",
    "term_count = 100\n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "qubits = kernel.qalloc(qubit_count)\n",
    "kernel.h(qubits[0])\n",
    "\n",
    "for i in range(1, qubit_count):\n",
    "    kernel.cx(qubits[0], qubits[i])\n",
    "\n",
    "# We create a random hamiltonian with several terms\n",
    "hamiltonian = cudaq.SpinOperator.random(qubit_count, term_count)\n",
    "\n",
    "# The observe calls allows us to calculate the expectation value of the Hamiltonian,\n",
    "# batches the terms, and distributes them over the multiple QPU's/GPUs.\n",
    "# expectation = cudaq.observe(kernel, hamiltonian)  # Single node, single GPU.\n",
    "\n",
    "expectation = cudaq.observe(kernel, hamiltonian, \n",
    "                        execution=cudaq.parallel.thread)  # Single node, multi-GPU.\n",
    "\n",
    "# expectation = cudaq.observe(kernel, hamiltonian, \n",
    "#                       execution= cudaq.parallel.mpi) # Multi-node, multi-GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    More on workflows enabled by the use of multiple gpus.\n",
    "    \n",
    "https://nvidia.github.io/cuda-quantum/latest/examples/python/tutorials/multi_gpu_workflows.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
